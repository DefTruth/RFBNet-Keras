{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import copy\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "#From keras\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "# from keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "from keras import optimizers,regularizers\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger\n",
    "\n",
    "# From ssd_keras\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "import ssd_encoder_decoder.ssd_output_decoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections\n",
    "from SSD_loss import SSDLoss\n",
    "from eval_utils.average_precision_evaluator import Evaluator\n",
    "from importlib import reload\n",
    "#import cv2\n",
    "from detector_help import process_y,post_process,prior_box\n",
    "import detection_nets,classification_nets\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from drawing import *\n",
    "from detection_nets import load_mobilenetv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_H = 300\n",
    "input_W = 300\n",
    "input_C = 3\n",
    "input_shape = (input_H, input_W, input_C)\n",
    "model_name = \"ssdlite_mn2\"\n",
    "root_path = \"/home/cai/dataset/VOCdevkit\"\n",
    "aspect_ratios = [[2,3],\n",
    "                 [2,3],\n",
    "                 [2,3],\n",
    "                 [2,3],\n",
    "                 [2],\n",
    "                 [2]]\n",
    "\n",
    "mean_color = [123, 117, 104] \n",
    "swap_channels = [2, 1, 0] # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "num_classes = 20 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "variances = [0.1, 0.1, 0.2, 0.2]\n",
    "# scale = [0.07, 0.15, 0.37, 0.54, 0.71, 0.88, 1.05]\n",
    "scale = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cai/.local/lib/python3.5/site-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 300, 300, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 301, 301, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 150, 150, 32) 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 150, 150, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 150, 150, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 150, 150, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 150, 150, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 150, 150, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 150, 150, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 150, 150, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 150, 150, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 150, 150, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 150, 150, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 151, 151, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 75, 75, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 75, 75, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 75, 75, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 75, 75, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 75, 75, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 75, 75, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 75, 75, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 75, 75, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 75, 75, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 75, 75, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 75, 75, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 75, 75, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 75, 75, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 75, 75, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 75, 75, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 75, 75, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 75, 75, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 77, 77, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 38, 38, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 38, 38, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 38, 38, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 38, 38, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 38, 38, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 38, 38, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 38, 38, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 38, 38, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 38, 38, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 38, 38, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 38, 38, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 38, 38, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 38, 38, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 38, 38, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 38, 38, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 38, 38, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 38, 38, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 38, 38, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 38, 38, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 38, 38, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 38, 38, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 38, 38, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 38, 38, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 38, 38, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 38, 38, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 38, 38, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 39, 39, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 19, 19, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 19, 19, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 19, 19, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 19, 19, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 19, 19, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 19, 19, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 19, 19, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 19, 19, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 19, 19, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 19, 19, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 19, 19, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 19, 19, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 19, 19, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 19, 19, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 19, 19, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 19, 19, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 19, 19, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 19, 19, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 19, 19, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 19, 19, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 19, 19, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 19, 19, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 19, 19, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 19, 19, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 19, 19, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 19, 19, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 19, 19, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 19, 19, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 19, 19, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 19, 19, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 19, 19, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 19, 19, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 19, 19, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 19, 19, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 19, 19, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 19, 19, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 19, 19, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 19, 19, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 19, 19, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 19, 19, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 19, 19, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 19, 19, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 19, 19, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 19, 19, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 19, 19, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 19, 19, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 19, 19, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 19, 19, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 19, 19, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 19, 19, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 19, 19, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 19, 19, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 19, 19, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 19, 19, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 19, 19, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 19, 19, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 19, 19, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 19, 19, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 19, 19, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 19, 19, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 19, 19, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 21, 21, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 10, 10, 576)  5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 10, 10, 576)  2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 10, 10, 576)  0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 10, 10, 160)  92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 10, 10, 160)  640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 10, 10, 960)  153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 10, 10, 960)  3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 10, 10, 960)  0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 10, 10, 960)  8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 10, 10, 960)  3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 10, 10, 960)  0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 10, 10, 160)  153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 10, 10, 160)  640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 10, 10, 160)  0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 10, 10, 960)  153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 10, 10, 960)  3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 10, 10, 960)  0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 10, 10, 960)  8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 10, 10, 960)  3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 10, 10, 960)  0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 10, 10, 160)  153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 10, 10, 160)  640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 10, 10, 160)  0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 10, 10, 960)  153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 10, 10, 960)  3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 10, 10, 960)  0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 10, 10, 960)  8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 10, 10, 960)  3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 10, 10, 960)  0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 10, 10, 320)  307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 10, 10, 320)  1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 10, 10, 1280) 409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 10, 10, 1280) 5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 10, 10, 1280) 0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "extra_3_conv (SeparableConv2D)  (None, 5, 5, 512)    666880      out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "extra_3_bn (BatchNormalization) (None, 5, 5, 512)    2048        extra_3_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "extra_4_conv (SeparableConv2D)  (None, 3, 3, 256)    135680      extra_3_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "extra_4_bn (BatchNormalization) (None, 3, 3, 256)    1024        extra_4_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "extra_5_conv (SeparableConv2D)  (None, 3, 3, 256)    67840       extra_4_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "extra_5_bn (BatchNormalization) (None, 3, 3, 256)    1024        extra_5_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "extra_6_conv (SeparableConv2D)  (None, 1, 1, 128)    35072       extra_5_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "extra_6_bn (BatchNormalization) (None, 1, 1, 128)    512         extra_6_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conf_0_conv (SeparableConv2D)   (None, 19, 19, 126)  77760       block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conf_1_conv (SeparableConv2D)   (None, 10, 10, 126)  172800      out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conf_2_conv (SeparableConv2D)   (None, 5, 5, 126)    69120       extra_3_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conf_3_conv (SeparableConv2D)   (None, 3, 3, 126)    34560       extra_4_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conf_4_conv (SeparableConv2D)   (None, 3, 3, 84)     23808       extra_5_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conf_5_conv (SeparableConv2D)   (None, 1, 1, 84)     11904       extra_6_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conf_0_bn (BatchNormalization)  (None, 19, 19, 126)  504         conf_0_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conf_1_bn (BatchNormalization)  (None, 10, 10, 126)  504         conf_1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conf_2_bn (BatchNormalization)  (None, 5, 5, 126)    504         conf_2_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conf_3_bn (BatchNormalization)  (None, 3, 3, 126)    504         conf_3_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conf_4_bn (BatchNormalization)  (None, 3, 3, 84)     336         conf_4_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conf_5_bn (BatchNormalization)  (None, 1, 1, 84)     336         conf_5_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loc_0_conv (SeparableConv2D)    (None, 19, 19, 24)   19008       block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "loc_1_conv (SeparableConv2D)    (None, 10, 10, 24)   42240       out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "loc_2_conv (SeparableConv2D)    (None, 5, 5, 24)     16896       extra_3_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "loc_3_conv (SeparableConv2D)    (None, 3, 3, 24)     8448        extra_4_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "loc_4_conv (SeparableConv2D)    (None, 3, 3, 16)     6400        extra_5_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "loc_5_conv (SeparableConv2D)    (None, 1, 1, 16)     3200        extra_6_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_conf_0 (Reshape)        (None, 2166, 21)     0           conf_0_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_conf_1 (Reshape)        (None, 600, 21)      0           conf_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_conf_2 (Reshape)        (None, 150, 21)      0           conf_2_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_conf_3 (Reshape)        (None, 54, 21)       0           conf_3_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_conf_4 (Reshape)        (None, 36, 21)       0           conf_4_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_conf_5 (Reshape)        (None, 4, 21)        0           conf_5_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loc_0_bn (BatchNormalization)   (None, 19, 19, 24)   96          loc_0_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "loc_1_bn (BatchNormalization)   (None, 10, 10, 24)   96          loc_1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "loc_2_bn (BatchNormalization)   (None, 5, 5, 24)     96          loc_2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "loc_3_bn (BatchNormalization)   (None, 3, 3, 24)     96          loc_3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "loc_4_bn (BatchNormalization)   (None, 3, 3, 16)     64          loc_4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "loc_5_bn (BatchNormalization)   (None, 1, 1, 16)     64          loc_5_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf_merge (Concatenate)   (None, 3010, 21)     0           reshape_conf_0[0][0]             \n",
      "                                                                 reshape_conf_1[0][0]             \n",
      "                                                                 reshape_conf_2[0][0]             \n",
      "                                                                 reshape_conf_3[0][0]             \n",
      "                                                                 reshape_conf_4[0][0]             \n",
      "                                                                 reshape_conf_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_loc_0 (Reshape)         (None, 2166, 4)      0           loc_0_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_loc_1 (Reshape)         (None, 600, 4)       0           loc_1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_loc_2 (Reshape)         (None, 150, 4)       0           loc_2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_loc_3 (Reshape)         (None, 54, 4)        0           loc_3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_loc_4 (Reshape)         (None, 36, 4)        0           loc_4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_loc_5 (Reshape)         (None, 4, 4)         0           loc_5_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, 3010, 21)     0           mbox_conf_merge[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mbox_loc_merge (Concatenate)    (None, 3010, 4)      0           reshape_loc_0[0][0]              \n",
      "                                                                 reshape_loc_1[0][0]              \n",
      "                                                                 reshape_loc_2[0][0]              \n",
      "                                                                 reshape_loc_3[0][0]              \n",
      "                                                                 reshape_loc_4[0][0]              \n",
      "                                                                 reshape_loc_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mbox_pred_merge (Concatenate)   (None, 3010, 25)     0           softmax_1[0][0]                  \n",
      "                                                                 mbox_loc_merge[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 3,657,408\n",
      "Trainable params: 3,619,392\n",
      "Non-trainable params: 38,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssdlite_mn2 has been built \n"
     ]
    }
   ],
   "source": [
    "reload(detection_nets)\n",
    "K.clear_session()\n",
    "build_model = detection_nets.build_ssdlite\n",
    "#Don`t tune learning rate here because we will use a lr scheduler in callbacks\n",
    "#Orignal paper used SGD but according to the author of ssd_keras, use adam is better \n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3,alpha=1.0)\n",
    "base_model = load_mobilenetv2()\n",
    "#     base_model.summary()\n",
    "prior_config =  [2 + len(ar) * 2 for ar in aspect_ratios]  # number of boxes per feature map location\n",
    "source_layer = \"block_12_expand\"\n",
    "model = build_model(base_model = base_model,\n",
    "               prior_config = prior_config,\n",
    "               source_layer_name_1 = source_layer,\n",
    "               num_classes = num_classes)\n",
    "\n",
    "\n",
    "# for layer in model.layers[:120]:\n",
    "#     layer.trainable = False\n",
    "model.summary()                       #Comment this line if you don`t want to show summary every time you build your model\n",
    "\n",
    "model = detection_nets.preprocess(input_shape,model,mean_color,swap_channels)\n",
    "# model = multi_gpu_model(model,gpus=2) #Comment it if don`t use multi_gpu \n",
    "model.compile(adam,\n",
    "              loss=ssd_loss.loss,\n",
    "              metrics = [ssd_loss.class_loss,ssd_loss.loc_loss]\n",
    "              )\n",
    "print(model_name,'has been built ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previously trained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model_path = \"ssdlite_mn2_pascal_07+12_Final.h5\"\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3,alpha=1.0)\n",
    "# #Load old model\n",
    "# model.compile(adam,\n",
    "#               loss=ssd_loss.loss,\n",
    "#               metrics = [ssd_loss.class_loss,ssd_loss.loc_loss]\n",
    "#               )\n",
    "# model = multi_gpu_model(model,gpus=2) #Comment it if don`t use multi_gpu \n",
    "model = load_model(model_path,custom_objects={'loss': ssd_loss.loss,'class_loss':ssd_loss.class_loss,'loc_loss':ssd_loss.loc_loss})\n",
    "#model = load_model(model_path,custom_objects={'loss': ssd_loss.loss,'class loss': ssd_loss.class_loss, 'loc loss': ssd_loss.loc_loss})\n",
    "print(\"load model from\",model_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "batch_n = 100\n",
    "img_height = 300\n",
    "img_width = 300\n",
    "img_channels = 3\n",
    "# detector = Detect(num_classes,0,cfg)\n",
    "batch_size_range = [1,2,4,8,16,32]#[1,2,4,8]\n",
    "print('Start testing...')\n",
    "for batch_size in batch_size_range:\n",
    "    time_total = 0\n",
    "    time_net = 0\n",
    "    time_post = 0\n",
    "    print('batch size',batch_size)\n",
    "    for i in range(0,batch_n):\n",
    "        test_batch = np.random.rand(batch_size,img_height,img_width,img_channels)\n",
    "        click = time.time()\n",
    "        y_pred = model.predict(test_batch)\n",
    "        time_net += (time.time() - click)\n",
    "        click = time.time()\n",
    "        y_pred_decoded = decode_detections(y_pred,\n",
    "                          priors,variances,\n",
    "                          img_height = input_H,\n",
    "                          img_width = input_W,\n",
    "                          confidence_thresh = 0.5,\n",
    "                          iou_threshold = 0.45)\n",
    "        time_post += (time.time() - click)\n",
    "    time_total = time_net + time_post\n",
    "    print('Time cost per batch: %.3f FPS: %.1f'%(time_total / batch_n,batch_n*batch_size/ time_total))\n",
    "    print('Time(pure forward) cost per batch: %.3f FPS: %.1F'%(time_net / batch_n, batch_n*batch_size/ time_net))\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define featue map as predictor size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_map_300 = [38,19,10,5,3,1]\n",
    "feature_map_300 = [19,10,5,3,3,1]\n",
    "feature_map_224 = [7,7,4,4,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define class_names\n",
    "class_names = ['background',\n",
    "           'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "           'bottle', 'bus', 'car', 'cat',\n",
    "           'chair', 'cow', 'diningtable', 'dog',\n",
    "           'horse', 'motorbike', 'person', 'pottedplant',\n",
    "           'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "force_create_dataset = False #Force data generator to load dataset from source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels: 100%|██████████| 16551/16551 [00:04<00:00, 3656.43it/s]\n",
      "Loading image IDs: 100%|██████████| 16551/16551 [00:02<00:00, 7886.31it/s]\n",
      "Loading evaluation-neutrality annotations: 100%|██████████| 16551/16551 [00:02<00:00, 6276.41it/s]\n",
      "Loading labels: 100%|██████████| 4952/4952 [00:01<00:00, 3646.93it/s]\n",
      "Loading image IDs: 100%|██████████| 4952/4952 [00:00<00:00, 8293.43it/s]\n",
      "Loading evaluation-neutrality annotations: 100%|██████████| 4952/4952 [00:00<00:00, 6149.08it/s]\n"
     ]
    }
   ],
   "source": [
    "root_path = '/home/cai/dataset/VOCdevkit'\n",
    "trainset_hdf5_path = 'dataset_pascal_voc_07+12_trainval.h5'\n",
    "valset_hdf5_path = 'dataset_pascal_voc_07_test.h5'\n",
    "\n",
    "# The directories that contain the images.\n",
    "VOC_2007_images_dir      = root_path + '/VOC2007/JPEGImages/'\n",
    "VOC_2012_images_dir      = root_path + '/VOC2012/JPEGImages/'\n",
    "\n",
    "# The directories that contain the annotations.\n",
    "VOC_2007_annotations_dir      = root_path + '/VOC2007/Annotations/'\n",
    "VOC_2012_annotations_dir      = root_path + '/VOC2012/Annotations/'\n",
    "\n",
    "# The paths to the image sets.\n",
    "VOC_2007_train_image_set_filename    = root_path + '/VOC2007/ImageSets/Main/train.txt'\n",
    "VOC_2012_train_image_set_filename    = root_path + '/VOC2012/ImageSets/Main/train.txt'\n",
    "VOC_2007_val_image_set_filename      = root_path + '/VOC2007/ImageSets/Main/val.txt'\n",
    "VOC_2012_val_image_set_filename      = root_path + '/VOC2012/ImageSets/Main/val.txt'\n",
    "VOC_2007_trainval_image_set_filename = root_path + '/VOC2007/ImageSets/Main/trainval.txt'\n",
    "VOC_2012_trainval_image_set_filename = root_path + '/VOC2012/ImageSets/Main/trainval.txt'\n",
    "VOC_2007_test_image_set_filename     = root_path + '/VOC2007/ImageSets/Main/test.txt'\n",
    "\n",
    "if os.path.isfile(trainset_hdf5_path) and os.path.isfile(valset_hdf5_path) and not force_create_dataset:\n",
    "    #Load dataset from created hdf5_dataset\n",
    "    train_dataset = DataGenerator(hdf5_dataset_path = trainset_hdf5_path)\n",
    "    val_dataset = DataGenerator(hdf5_dataset_path = valset_hdf5_path)\n",
    "else:\n",
    "    train_dataset = DataGenerator()\n",
    "    val_dataset = DataGenerator()\n",
    "    \n",
    "    train_dataset.parse_xml(images_dirs=[VOC_2007_images_dir,\n",
    "                                         VOC_2012_images_dir],\n",
    "                            image_set_filenames=[VOC_2007_trainval_image_set_filename,\n",
    "                                                 VOC_2012_trainval_image_set_filename],\n",
    "                            annotations_dirs=[VOC_2007_annotations_dir,\n",
    "                                              VOC_2012_annotations_dir],\n",
    "                            classes=class_names,\n",
    "                            include_classes='all',\n",
    "                            exclude_truncated=False,\n",
    "                            exclude_difficult=False,\n",
    "                            ret=False)\n",
    "\n",
    "    val_dataset.parse_xml(images_dirs=[VOC_2007_images_dir],\n",
    "                          image_set_filenames=[VOC_2007_test_image_set_filename],\n",
    "                          annotations_dirs=[VOC_2007_annotations_dir],\n",
    "                          classes=class_names,\n",
    "                          include_classes='all',\n",
    "                          exclude_truncated=False,\n",
    "                          exclude_difficult=True,\n",
    "                          ret=False)\n",
    "    train_dataset.create_hdf5_dataset(file_path=trainset_hdf5_path,\n",
    "                                      resize=False,\n",
    "                                      variable_image_size=True,\n",
    "                                      verbose=True)\n",
    "\n",
    "    val_dataset.create_hdf5_dataset(file_path=valset_hdf5_path,\n",
    "                                    resize=False,\n",
    "                                    variable_image_size=True,\n",
    "                                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of priors:\t  3010\n",
      "Number of images in the training dataset:\t 16551\n",
      "Number of images in the validation dataset:\t  4952\n"
     ]
    }
   ],
   "source": [
    "import detector_help\n",
    "reload(detector_help)\n",
    "from detector_help import *\n",
    "import data_augment\n",
    "reload(data_augment)\n",
    "from data_augment import *\n",
    "\n",
    "batch_size = 32\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=input_H,\n",
    "                                            img_width=input_W,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=input_H, width=input_W)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "priors = prior_box(feature_map_300,aspect_ratios,scale = scale,clip = False)\n",
    "label_encoder = LabelEncoder(num_classes,priors,variances,input_H,input_W)\n",
    "\n",
    "# ssd_input_encoder = SSDInputEncoder(img_height=input_H,\n",
    "#                                     img_width=input_W,\n",
    "#                                     n_classes=num_classes,\n",
    "#                                     predictor_sizes=feature_map,\n",
    "#                                     scales=scales,\n",
    "#                                     aspect_ratios_per_layer=aspect_ratios,\n",
    "#                                     two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "#                                     steps=steps,\n",
    "#                                     offsets=offsets,\n",
    "#                                     clip_boxes=clip_boxes,\n",
    "#                                     variances=variances,\n",
    "#                                     matching_type='multi',\n",
    "#                                     pos_iou_threshold=0.5,\n",
    "#                                     neg_iou_limit=0.5,\n",
    "#                                     normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=label_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=label_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "print(\"Number of priors:\\t{:>6}\".format(len(priors)))\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Set file path\n",
    "weights_folder = 'saved_weights/'\n",
    "\n",
    "if not os.path.isdir(weights_folder):\n",
    "    os.mkdir(weights_folder)\n",
    "\n",
    "checkpoint_filepath = weights_folder + model_name + '_pascal_07+12_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5'\n",
    "log_filepath = model_name + '_pascal_07+12_training_log.csv' \n",
    "#2. Define lr schedule function\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 70:\n",
    "        return 0.0005\n",
    "    elif epoch < 110:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 1e-5\n",
    "    \n",
    "#3. ## Define callbacks\n",
    "model_checkpoint = ModelCheckpoint(filepath = checkpoint_filepath,\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=5)\n",
    "\n",
    "csv_logger = CSVLogger(filename=log_filepath,\n",
    "                           separator=',',\n",
    "                           append=True)\n",
    "\n",
    "learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule,\n",
    "                                                verbose=1)\n",
    "\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             learning_rate_scheduler,\n",
    "             terminate_on_nan]\n",
    "# callbacks = [csv_logger,learning_rate_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw a batch of images(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flow_origin = train_dataset.generate(batch_size = 4,\n",
    "                                           transformations=[], \n",
    "                                           label_encoder = label_encoder,\n",
    "                                           returns = ['original_images','original_labels'])\n",
    "images,labels = next(train_flow_origin)\n",
    "for img,label in zip(images, labels):\n",
    "    draw_detection(img,label,class_names)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug encoder-decoder and data augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import detector_help\n",
    "reload(detector_help)\n",
    "import ssd_encoder_decoder.ssd_output_decoder\n",
    "reload(ssd_encoder_decoder.ssd_output_decoder)\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections\n",
    "from detector_help import LabelEncoder\n",
    "priors = prior_box(feature_map_300,aspect_ratios,scale = scale,clip = False)\n",
    "label_encoder = LabelEncoder(num_classes,priors,variances,input_H,input_W)\n",
    "train_flow_encode = train_dataset.generate(batch_size = 4,\n",
    "                                           transformations= [convert_to_3_channels,\n",
    "                                                      resize], \n",
    "                                           label_encoder = label_encoder,\n",
    "                                           shuffle = False,\n",
    "                                           returns=[\"processed_images\",\"processed_labels\",\"encoded_labels\"])\n",
    "\n",
    "images,enc_labels,proc_labels = next(train_flow_encode)\n",
    "enc_labels_custom = detector_help.post_process(enc_labels,\n",
    "                                               priors,\n",
    "                                               variances,\n",
    "                                               num_classes,\n",
    "                                               input_H,input_W, \n",
    "                                               score_thresh = 0.06,   \n",
    "                                               iou_thresh = 0.01,\n",
    "                                               top_k = 1000) # Use top_k as 1000 because all gt labels`s conf are 1\n",
    "enc_labels_default = decode_detections(enc_labels,\n",
    "                  priors,\n",
    "                  np.array(variances),\n",
    "                  img_height = input_H,\n",
    "                  img_width = input_W,\n",
    "                  confidence_thresh = 0.06,\n",
    "                  iou_threshold = 0.45)\n",
    "\n",
    "for img,enc_default_label,enc_custom_label,proc_label in zip(images,enc_labels_default,enc_labels_custom,proc_labels):\n",
    "#     print(enc_custom_label)\n",
    "    draw_detection(img, proc_label, class_names, color = 'green')\n",
    "    #plt.title('Default decoder')\n",
    "    #draw_detection(img, enc_default_label, class_names, color = 'red')\n",
    "   # plt.title('Custom decoder')\n",
    "    draw_detection(img, enc_default_label, class_names, color = 'purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "base_img = np.zeros((300,300,3))\n",
    "plt.imshow(base_img)\n",
    "current_axis = plt.gca()\n",
    "print(len(priors))\n",
    "for k,box in enumerate(priors[4:6*38:6]):\n",
    "#     plt.imshow(base_img)\n",
    "#     current_axis = plt.gca()\n",
    "#     if k%100 == 0:\n",
    "#         base_img = np.zeros((300,300,3))\n",
    "#         #plt.imshow(base_img)\n",
    "#         current_axis = plt.gca()\n",
    "    xmid,ymid,w,h = box[-4:]\n",
    "    xmid *= 300\n",
    "    ymid *= 300\n",
    "    w *= 300\n",
    "    h *= 300\n",
    "    if k < 1000:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'green'\n",
    "    current_axis.add_patch(plt.Rectangle((xmid - w/2, ymid - h/2), w,h, color=color, fill=False, linewidth=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If load weights from files,initial_epoch need to be set to the next epoch to be trained.\n",
    "initial_epoch = 0\n",
    "final_epochs = 120\n",
    "steps_per_epoch = 1000\n",
    "plot = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name ssdlite_mn2 \n",
      "start fitting..  inital epoch: 0 final epoch: 120 epoch step: 1000 plot_history: True \n",
      "trainset size: 16551  batch_size 32\n",
      "Epoch 1/120\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1007s 1s/step - loss: 13.6643 - class_loss: 11.7291 - loc_loss: 1.9352 - val_loss: 11.6596 - val_class_loss: 9.8883 - val_loc_loss: 1.7713\n",
      "Epoch 2/120\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1001s 1s/step - loss: 10.0089 - class_loss: 8.5372 - loc_loss: 1.4718 - val_loss: 10.1204 - val_class_loss: 8.4739 - val_loc_loss: 1.6466\n",
      "Epoch 3/120\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 990s 990ms/step - loss: 8.0206 - class_loss: 6.6712 - loc_loss: 1.3494 - val_loss: 7.4754 - val_class_loss: 5.9913 - val_loc_loss: 1.4841\n",
      "Epoch 4/120\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 984s 984ms/step - loss: 6.5998 - class_loss: 5.3063 - loc_loss: 1.2935 - val_loss: 6.3263 - val_class_loss: 4.8602 - val_loc_loss: 1.4660\n",
      "Epoch 5/120\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 989s 989ms/step - loss: 5.5904 - class_loss: 4.3391 - loc_loss: 1.2512 - val_loss: 5.5399 - val_class_loss: 4.1058 - val_loc_loss: 1.4340\n",
      "\n",
      "Epoch 00005: val_loss improved from inf to 5.53986, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-05_loss-5.5904_val_loss-5.5399.h5\n",
      "Epoch 6/120\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 994s 994ms/step - loss: 4.9231 - class_loss: 3.6981 - loc_loss: 1.2250 - val_loss: 4.9527 - val_class_loss: 3.5402 - val_loc_loss: 1.4125\n",
      "Epoch 7/120\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 998s 998ms/step - loss: 4.4765 - class_loss: 3.2832 - loc_loss: 1.1934 - val_loss: 4.6464 - val_class_loss: 3.2652 - val_loc_loss: 1.3812\n",
      "Epoch 8/120\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 999s 999ms/step - loss: 4.1793 - class_loss: 3.0083 - loc_loss: 1.1711 - val_loss: 4.6538 - val_class_loss: 3.2468 - val_loc_loss: 1.4070\n",
      "Epoch 9/120\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1007s 1s/step - loss: 3.9835 - class_loss: 2.8306 - loc_loss: 1.1529 - val_loss: 4.1397 - val_class_loss: 2.8830 - val_loc_loss: 1.2567\n",
      "Epoch 10/120\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 993s 993ms/step - loss: 3.8662 - class_loss: 2.7239 - loc_loss: 1.1423 - val_loss: 4.2850 - val_class_loss: 2.9415 - val_loc_loss: 1.3435\n",
      "\n",
      "Epoch 00010: val_loss improved from 5.53986 to 4.28502, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-10_loss-3.8657_val_loss-4.2850.h5\n",
      "Epoch 11/120\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1005s 1s/step - loss: 3.7340 - class_loss: 2.6264 - loc_loss: 1.1076 - val_loss: 3.9878 - val_class_loss: 2.7866 - val_loc_loss: 1.2012\n",
      "Epoch 12/120\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1015s 1s/step - loss: 3.6632 - class_loss: 2.5591 - loc_loss: 1.1041 - val_loss: 3.7473 - val_class_loss: 2.5661 - val_loc_loss: 1.1812\n",
      "Epoch 13/120\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1010s 1s/step - loss: 3.5909 - class_loss: 2.5045 - loc_loss: 1.0864 - val_loss: 3.8969 - val_class_loss: 2.6935 - val_loc_loss: 1.2034\n",
      "Epoch 14/120\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1029s 1s/step - loss: 3.5666 - class_loss: 2.4796 - loc_loss: 1.0870 - val_loss: 3.9898 - val_class_loss: 2.7425 - val_loc_loss: 1.2473\n",
      "Epoch 15/120\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1032s 1s/step - loss: 3.5168 - class_loss: 2.4490 - loc_loss: 1.0678 - val_loss: 3.7888 - val_class_loss: 2.6095 - val_loc_loss: 1.1792\n",
      "\n",
      "Epoch 00015: val_loss improved from 4.28502 to 3.78877, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-15_loss-3.5164_val_loss-3.7888.h5\n",
      "Epoch 16/120\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1015s 1s/step - loss: 3.4701 - class_loss: 2.4130 - loc_loss: 1.0570 - val_loss: 3.6372 - val_class_loss: 2.4898 - val_loc_loss: 1.1474\n",
      "Epoch 17/120\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1020s 1s/step - loss: 3.4388 - class_loss: 2.3876 - loc_loss: 1.0512 - val_loss: 3.6492 - val_class_loss: 2.4922 - val_loc_loss: 1.1570\n",
      "Epoch 18/120\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1029s 1s/step - loss: 3.4129 - class_loss: 2.3691 - loc_loss: 1.0438 - val_loss: 3.5513 - val_class_loss: 2.4513 - val_loc_loss: 1.1000\n",
      "Epoch 19/120\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1036s 1s/step - loss: 3.3793 - class_loss: 2.3458 - loc_loss: 1.0335 - val_loss: 3.3905 - val_class_loss: 2.3066 - val_loc_loss: 1.0839\n",
      "Epoch 20/120\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1037s 1s/step - loss: 3.3567 - class_loss: 2.3276 - loc_loss: 1.0291 - val_loss: 3.4943 - val_class_loss: 2.3806 - val_loc_loss: 1.1137\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.78877 to 3.49427, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-20_loss-3.3565_val_loss-3.4943.h5\n",
      "Epoch 21/120\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1012s 1s/step - loss: 3.3214 - class_loss: 2.3036 - loc_loss: 1.0179 - val_loss: 3.6095 - val_class_loss: 2.4956 - val_loc_loss: 1.1139\n",
      "Epoch 22/120\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1003s 1s/step - loss: 3.2953 - class_loss: 2.2845 - loc_loss: 1.0108 - val_loss: 3.4321 - val_class_loss: 2.3350 - val_loc_loss: 1.0971\n",
      "Epoch 23/120\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1006s 1s/step - loss: 3.2600 - class_loss: 2.2589 - loc_loss: 1.0011 - val_loss: 3.3803 - val_class_loss: 2.3023 - val_loc_loss: 1.0781\n",
      "Epoch 24/120\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1018s 1s/step - loss: 3.2499 - class_loss: 2.2475 - loc_loss: 1.0024 - val_loss: 3.4836 - val_class_loss: 2.3980 - val_loc_loss: 1.0856\n",
      "Epoch 25/120\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1024s 1s/step - loss: 3.2401 - class_loss: 2.2438 - loc_loss: 0.9963 - val_loss: 3.4669 - val_class_loss: 2.3516 - val_loc_loss: 1.1153\n",
      "\n",
      "Epoch 00025: val_loss improved from 3.49427 to 3.46691, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-25_loss-3.2386_val_loss-3.4669.h5\n",
      "Epoch 26/120\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1007s 1s/step - loss: 3.2010 - class_loss: 2.2109 - loc_loss: 0.9901 - val_loss: 3.3250 - val_class_loss: 2.2554 - val_loc_loss: 1.0696\n",
      "Epoch 27/120\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 1003s 1s/step - loss: 3.2007 - class_loss: 2.2140 - loc_loss: 0.9867 - val_loss: 3.2454 - val_class_loss: 2.2049 - val_loc_loss: 1.0405\n",
      "Epoch 28/120\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 987s 987ms/step - loss: 3.1701 - class_loss: 2.1950 - loc_loss: 0.9751 - val_loss: 3.2538 - val_class_loss: 2.2213 - val_loc_loss: 1.0324\n",
      "Epoch 29/120\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 985s 985ms/step - loss: 3.1490 - class_loss: 2.1741 - loc_loss: 0.9749 - val_loss: 3.2375 - val_class_loss: 2.2062 - val_loc_loss: 1.0313\n",
      "Epoch 30/120\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 992s 992ms/step - loss: 3.1589 - class_loss: 2.1821 - loc_loss: 0.9768 - val_loss: 3.2979 - val_class_loss: 2.2600 - val_loc_loss: 1.0379\n",
      "\n",
      "Epoch 00030: val_loss improved from 3.46691 to 3.29792, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-30_loss-3.1573_val_loss-3.2979.h5\n",
      "Epoch 31/120\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 979s 979ms/step - loss: 3.1261 - class_loss: 2.1581 - loc_loss: 0.9680 - val_loss: 3.1802 - val_class_loss: 2.1680 - val_loc_loss: 1.0122\n",
      "Epoch 32/120\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 985s 985ms/step - loss: 3.1117 - class_loss: 2.1467 - loc_loss: 0.9650 - val_loss: 3.2442 - val_class_loss: 2.1942 - val_loc_loss: 1.0499\n",
      "Epoch 33/120\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0005.\n",
      " 147/1000 [===>..........................] - ETA: 12:50 - loss: 3.1400 - class_loss: 2.1607 - loc_loss: 0.9793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 981s 981ms/step - loss: 3.0621 - class_loss: 2.1108 - loc_loss: 0.9513 - val_loss: 3.2451 - val_class_loss: 2.2229 - val_loc_loss: 1.0222\n",
      "\n",
      "Epoch 00035: val_loss improved from 3.29792 to 3.24512, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-35_loss-3.0611_val_loss-3.2451.h5\n",
      "Epoch 36/120\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 976s 976ms/step - loss: 3.0589 - class_loss: 2.1125 - loc_loss: 0.9464 - val_loss: 3.2151 - val_class_loss: 2.1966 - val_loc_loss: 1.0185\n",
      "Epoch 37/120\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 984s 984ms/step - loss: 3.0572 - class_loss: 2.1087 - loc_loss: 0.9485 - val_loss: 3.2914 - val_class_loss: 2.2582 - val_loc_loss: 1.0332\n",
      "Epoch 38/120\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 984s 984ms/step - loss: 3.0220 - class_loss: 2.0800 - loc_loss: 0.9419 - val_loss: 3.3689 - val_class_loss: 2.3068 - val_loc_loss: 1.0620\n",
      "Epoch 39/120\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 979s 979ms/step - loss: 3.0155 - class_loss: 2.0770 - loc_loss: 0.9386 - val_loss: 3.1550 - val_class_loss: 2.1381 - val_loc_loss: 1.0169\n",
      "Epoch 40/120\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 979s 979ms/step - loss: 3.0243 - class_loss: 2.0829 - loc_loss: 0.9413 - val_loss: 3.1540 - val_class_loss: 2.1577 - val_loc_loss: 0.9963\n",
      "\n",
      "Epoch 00040: val_loss improved from 3.24512 to 3.15399, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-40_loss-3.0243_val_loss-3.1540.h5\n",
      "Epoch 41/120\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 980s 980ms/step - loss: 2.9848 - class_loss: 2.0612 - loc_loss: 0.9236 - val_loss: 3.1599 - val_class_loss: 2.1637 - val_loc_loss: 0.9962\n",
      "Epoch 42/120\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 984s 984ms/step - loss: 2.9804 - class_loss: 2.0541 - loc_loss: 0.9263 - val_loss: 3.3101 - val_class_loss: 2.2844 - val_loc_loss: 1.0256\n",
      "Epoch 43/120\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 976s 976ms/step - loss: 2.9646 - class_loss: 2.0474 - loc_loss: 0.9172 - val_loss: 3.1909 - val_class_loss: 2.1817 - val_loc_loss: 1.0092\n",
      "Epoch 44/120\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 983s 983ms/step - loss: 2.9464 - class_loss: 2.0328 - loc_loss: 0.9136 - val_loss: 3.1885 - val_class_loss: 2.1964 - val_loc_loss: 0.9921\n",
      "Epoch 45/120\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 978s 978ms/step - loss: 2.9519 - class_loss: 2.0350 - loc_loss: 0.9169 - val_loss: 3.1403 - val_class_loss: 2.1525 - val_loc_loss: 0.9878\n",
      "\n",
      "Epoch 00045: val_loss improved from 3.15399 to 3.14035, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-45_loss-2.9506_val_loss-3.1403.h5\n",
      "Epoch 46/120\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 977s 977ms/step - loss: 2.9201 - class_loss: 2.0121 - loc_loss: 0.9079 - val_loss: 3.1857 - val_class_loss: 2.1834 - val_loc_loss: 1.0023\n",
      "Epoch 47/120\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 965s 965ms/step - loss: 2.9351 - class_loss: 2.0274 - loc_loss: 0.9076 - val_loss: 3.1578 - val_class_loss: 2.1490 - val_loc_loss: 1.0089\n",
      "Epoch 48/120\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 979s 979ms/step - loss: 2.9320 - class_loss: 2.0186 - loc_loss: 0.9134 - val_loss: 3.1155 - val_class_loss: 2.1305 - val_loc_loss: 0.9850\n",
      "Epoch 49/120\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 987s 987ms/step - loss: 2.9304 - class_loss: 2.0195 - loc_loss: 0.9109 - val_loss: 3.1386 - val_class_loss: 2.1560 - val_loc_loss: 0.9826\n",
      "Epoch 50/120\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 980s 980ms/step - loss: 2.8817 - class_loss: 1.9906 - loc_loss: 0.8911 - val_loss: 3.1817 - val_class_loss: 2.1787 - val_loc_loss: 1.0031\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.14035\n",
      "Epoch 51/120\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 986s 986ms/step - loss: 2.8785 - class_loss: 1.9816 - loc_loss: 0.8969 - val_loss: 3.0884 - val_class_loss: 2.1171 - val_loc_loss: 0.9713\n",
      "Epoch 52/120\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 985s 985ms/step - loss: 2.8848 - class_loss: 1.9864 - loc_loss: 0.8984 - val_loss: 3.1289 - val_class_loss: 2.1494 - val_loc_loss: 0.9796\n",
      "Epoch 53/120\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 994s 994ms/step - loss: 2.8745 - class_loss: 1.9758 - loc_loss: 0.8987 - val_loss: 3.1127 - val_class_loss: 2.1293 - val_loc_loss: 0.9834\n",
      "Epoch 54/120\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 992s 992ms/step - loss: 2.8641 - class_loss: 1.9686 - loc_loss: 0.8955 - val_loss: 3.1239 - val_class_loss: 2.1452 - val_loc_loss: 0.9787\n",
      "Epoch 55/120\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 989s 989ms/step - loss: 2.8725 - class_loss: 1.9760 - loc_loss: 0.8966 - val_loss: 3.1028 - val_class_loss: 2.1242 - val_loc_loss: 0.9786\n",
      "\n",
      "Epoch 00055: val_loss improved from 3.14035 to 3.10279, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-55_loss-2.8714_val_loss-3.1028.h5\n",
      "Epoch 56/120\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 995s 995ms/step - loss: 2.8540 - class_loss: 1.9617 - loc_loss: 0.8922 - val_loss: 3.1195 - val_class_loss: 2.1405 - val_loc_loss: 0.9790\n",
      "Epoch 57/120\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 989s 989ms/step - loss: 2.8381 - class_loss: 1.9522 - loc_loss: 0.8859 - val_loss: 3.1294 - val_class_loss: 2.1516 - val_loc_loss: 0.9778\n",
      "Epoch 58/120\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 994s 994ms/step - loss: 2.8518 - class_loss: 1.9600 - loc_loss: 0.8918 - val_loss: 3.0914 - val_class_loss: 2.1213 - val_loc_loss: 0.9701\n",
      "Epoch 59/120\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 993s 993ms/step - loss: 2.8460 - class_loss: 1.9582 - loc_loss: 0.8878 - val_loss: 3.0717 - val_class_loss: 2.0989 - val_loc_loss: 0.9728\n",
      "Epoch 60/120\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 989s 989ms/step - loss: 2.8163 - class_loss: 1.9389 - loc_loss: 0.8773 - val_loss: 3.0932 - val_class_loss: 2.1286 - val_loc_loss: 0.9646\n",
      "\n",
      "Epoch 00060: val_loss improved from 3.10279 to 3.09324, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-60_loss-2.8167_val_loss-3.0932.h5\n",
      "Epoch 61/120\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 991s 991ms/step - loss: 2.8201 - class_loss: 1.9366 - loc_loss: 0.8836 - val_loss: 3.0820 - val_class_loss: 2.1264 - val_loc_loss: 0.9556\n",
      "Epoch 62/120\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 983s 983ms/step - loss: 2.7998 - class_loss: 1.9266 - loc_loss: 0.8732 - val_loss: 3.0715 - val_class_loss: 2.1179 - val_loc_loss: 0.9536\n",
      "Epoch 63/120\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 993s 993ms/step - loss: 2.8158 - class_loss: 1.9433 - loc_loss: 0.8724 - val_loss: 3.0635 - val_class_loss: 2.1096 - val_loc_loss: 0.9540\n",
      "Epoch 64/120\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 988s 988ms/step - loss: 2.7854 - class_loss: 1.9261 - loc_loss: 0.8593 - val_loss: 3.1337 - val_class_loss: 2.1716 - val_loc_loss: 0.9621\n",
      "Epoch 65/120\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 987s 987ms/step - loss: 2.7707 - class_loss: 1.9171 - loc_loss: 0.8536 - val_loss: 3.1187 - val_class_loss: 2.1588 - val_loc_loss: 0.9600\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.09324\n",
      "Epoch 66/120\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 991s 991ms/step - loss: 2.7747 - class_loss: 1.9179 - loc_loss: 0.8568 - val_loss: 3.0452 - val_class_loss: 2.0949 - val_loc_loss: 0.9503\n",
      "Epoch 67/120\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 979s 979ms/step - loss: 2.7624 - class_loss: 1.9061 - loc_loss: 0.8563 - val_loss: 3.0249 - val_class_loss: 2.0714 - val_loc_loss: 0.9535\n",
      "Epoch 68/120\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 984s 984ms/step - loss: 2.7657 - class_loss: 1.9110 - loc_loss: 0.8547 - val_loss: 3.0017 - val_class_loss: 2.0763 - val_loc_loss: 0.9254\n",
      "Epoch 69/120\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 988s 988ms/step - loss: 2.7363 - class_loss: 1.8900 - loc_loss: 0.8463 - val_loss: 3.1029 - val_class_loss: 2.1473 - val_loc_loss: 0.9556\n",
      "Epoch 70/120\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0005.\n",
      "1000/1000 [==============================] - 984s 984ms/step - loss: 2.7430 - class_loss: 1.8938 - loc_loss: 0.8492 - val_loss: 3.0556 - val_class_loss: 2.1079 - val_loc_loss: 0.9477\n",
      "\n",
      "Epoch 00070: val_loss improved from 3.09324 to 3.05560, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-70_loss-2.7416_val_loss-3.0556.h5\n",
      "Epoch 71/120\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.0001.\n",
      " 591/1000 [================>.............] - ETA: 6:31 - loss: 2.6274 - class_loss: 1.8024 - loc_loss: 0.8250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 981s 981ms/step - loss: 2.5221 - class_loss: 1.7274 - loc_loss: 0.7947 - val_loss: 2.7779 - val_class_loss: 1.9127 - val_loc_loss: 0.8652\n",
      "\n",
      "Epoch 00075: val_loss improved from 3.05560 to 2.77791, saving model to saved_weights/ssdlite_mn2_pascal_07+12_epoch-75_loss-2.5217_val_loss-2.7779.h5\n",
      "Epoch 76/120\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 982s 982ms/step - loss: 2.5406 - class_loss: 1.7432 - loc_loss: 0.7974 - val_loss: 2.7790 - val_class_loss: 1.9129 - val_loc_loss: 0.8662\n",
      "Epoch 77/120\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 980s 980ms/step - loss: 2.5039 - class_loss: 1.7162 - loc_loss: 0.7877 - val_loss: 2.7807 - val_class_loss: 1.9179 - val_loc_loss: 0.8628\n",
      "Epoch 78/120\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.0001.\n",
      " 460/1000 [============>.................] - ETA: 8:26 - loss: 2.5174 - class_loss: 1.7271 - loc_loss: 0.7903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 982s 982ms/step - loss: 2.4875 - class_loss: 1.7058 - loc_loss: 0.7818 - val_loss: 2.7798 - val_class_loss: 1.9165 - val_loc_loss: 0.8633\n",
      "Epoch 80/120\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 983s 983ms/step - loss: 2.4831 - class_loss: 1.7019 - loc_loss: 0.7812 - val_loss: 2.8023 - val_class_loss: 1.9388 - val_loc_loss: 0.8635\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.77791\n",
      "Epoch 81/120\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 758s 758ms/step - loss: 2.4751 - class_loss: 1.6997 - loc_loss: 0.7754 - val_loss: 2.7908 - val_class_loss: 1.9278 - val_loc_loss: 0.8630\n",
      "Epoch 82/120\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 750s 750ms/step - loss: 2.4784 - class_loss: 1.7002 - loc_loss: 0.7781 - val_loss: 2.7894 - val_class_loss: 1.9244 - val_loc_loss: 0.8650\n",
      "Epoch 83/120\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 749s 749ms/step - loss: 2.4821 - class_loss: 1.7001 - loc_loss: 0.7820 - val_loss: 2.7685 - val_class_loss: 1.9133 - val_loc_loss: 0.8552\n",
      "Epoch 84/120\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.0001.\n",
      "  47/1000 [>.............................] - ETA: 9:24 - loss: 2.4132 - class_loss: 1.6650 - loc_loss: 0.7482"
     ]
    }
   ],
   "source": [
    "print('model name' ,model_name , \\\n",
    "       '\\nstart fitting.. ' , \n",
    "       'inital epoch:', initial_epoch,\n",
    "       'final epoch:', final_epochs,\n",
    "       'epoch step:', steps_per_epoch,\n",
    "       'plot_history:' ,plot, \\\n",
    "       '\\ntrainset size:',  train_dataset.get_dataset_size(), ' batch_size', batch_size )     \n",
    "\n",
    "validation_steps =  val_dataset.get_dataset_size() // batch_size\n",
    "history = model.fit_generator(train_generator,\n",
    "                              use_multiprocessing = True, \n",
    "                              steps_per_epoch = steps_per_epoch, \n",
    "                              validation_data = val_generator,\n",
    "                              validation_steps = validation_steps, \n",
    "                              epochs = final_epochs,\n",
    "                              callbacks = callbacks,\n",
    "                              initial_epoch = initial_epoch)\n",
    "\n",
    "if plot:\n",
    "    plot_history(history)\n",
    "    plt.savefig('./rfbmn2_300_pascal07+12_train.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[-1].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils.average_precision_evaluator\n",
    "reload(eval_utils.average_precision_evaluator)\n",
    "from eval_utils.average_precision_evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DataGenerator()\n",
    "test_dataset.parse_xml(images_dirs=[VOC_2007_images_dir],\n",
    "                      image_set_filenames=[VOC_2007_test_image_set_filename],\n",
    "                      annotations_dirs=[VOC_2007_annotations_dir],\n",
    "                      classes=class_names,\n",
    "                      include_classes='all',\n",
    "                      exclude_truncated=False,\n",
    "                      exclude_difficult=False,\n",
    "                      ret=False)\n",
    "print('Test size', test_dataset.get_dataset_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model=model,\n",
    "                      n_classes=num_classes,\n",
    "                      data_generator=test_dataset,\n",
    "                      model_mode='training')\n",
    "\n",
    "results = evaluator(img_height=input_H,\n",
    "                    img_width=input_W,\n",
    "                    batch_size=batch_size,\n",
    "                    priors = priors,\n",
    "                    variances = variances,\n",
    "                    data_generator_mode='resize',\n",
    "                    round_confidences=False,\n",
    "                    matching_iou_threshold=0.5,\n",
    "                    border_pixels='include',\n",
    "                    sorting_algorithm='quicksort',\n",
    "                    average_precision_mode='sample',\n",
    "                    num_recall_points=11,\n",
    "                    ignore_neutral_boxes=True,\n",
    "                    return_precisions=True,\n",
    "                    return_recalls=True,\n",
    "                    return_average_precisions=True,\n",
    "                    verbose=True)\n",
    "\n",
    "mean_average_precision, average_precisions, precisions, recalls = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, len(average_precisions)):\n",
    "    print(\"{:<14}{:<6}{}\".format(class_names[i], 'AP', round(average_precisions[i], 3)))\n",
    "print()\n",
    "print(\"{:<14}{:<6}{}\".format('','mAP', round(mean_average_precision, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = max((num_classes + 1) // 2, 2)\n",
    "n = 2\n",
    "\n",
    "fig, cells = plt.subplots(m, n, figsize=(n*8,m*8))\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        if n*i+j+1 > num_classes: break\n",
    "        cells[i, j].plot(recalls[n*i+j+1], precisions[n*i+j+1], color='blue', linewidth=1.0)\n",
    "        cells[i, j].set_xlabel('recall', fontsize=14)\n",
    "        cells[i, j].set_ylabel('precision', fontsize=14)\n",
    "        cells[i, j].grid(True)\n",
    "        cells[i, j].set_xticks(np.linspace(0,1,11))\n",
    "        cells[i, j].set_yticks(np.linspace(0,1,11))\n",
    "        cells[i, j].set_title(\"{}, AP: {:.3f}\".format(class_names[n*i+j+1], average_precisions[n*i+j+1]), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Set the generator for the predictions.\n",
    "\n",
    "predict_generator = val_dataset.generate(batch_size=1,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[convert_to_3_channels,\n",
    "                                                          resize],\n",
    "                                         label_encoder=None,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'inverse_transform',\n",
    "                                                  'original_images',\n",
    "                                                  'original_labels'},\n",
    "                                         keep_images_without_gt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate batch_items\n",
    "batch_images, batch_inverse_transforms, batch_original_images, batch_original_labels = next(predict_generator)\n",
    "\n",
    "i = 0 # Which batch item to look at\n",
    "\n",
    "#print(\"Image:\", batch_filenames[i])\n",
    "print()\n",
    "print(\"Ground truth boxes:\\n\")\n",
    "print(np.array(batch_original_labels[i]))\n",
    "\n",
    "\n",
    "# 3: Make predictions.\n",
    "y_pred = model.predict(batch_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: Decode labels\n",
    "reload(detector_help)\n",
    "y_pred_decoded = decode_detections(y_pred,\n",
    "                  priors,variances,\n",
    "                  img_height = input_H,\n",
    "                  img_width = input_W,\n",
    "                  confidence_thresh = 0.5,\n",
    "                  iou_threshold = 0.45)\n",
    "# y_pred_decoded = detector_help.post_process(y_pred, \n",
    "#                                             priors,\n",
    "#                                             num_classes,\n",
    "#                                             input_H, \n",
    "#                                             input_W,\n",
    "#                                             score_thresh = 0.5,\n",
    "#                                             iou_thresh = 0.4)\n",
    "y_pred_decoded_inv = apply_inverse_transforms(y_pred_decoded, batch_inverse_transforms)\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "print(\"Predicted boxes:\\n\")\n",
    "print('   class   conf xmin   ymin   xmax   ymax')\n",
    "print(y_pred_decoded_inv[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5: Draw \n",
    "colors = plt.cm.hsv(np.linspace(0, 1, num_classes+1)).tolist()\n",
    "draw_detection(batch_original_images[i],y_pred_decoded_inv[i],class_names,\n",
    "               show = True, draw_score = True,use_cm = True,color = colors, size = 'medium')\n",
    "draw_detection(batch_original_images[i],batch_original_labels[i],class_names, size = 'medium')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = \"data/dog3.jpg\"\n",
    "img = cv2.imread(img_file)\n",
    "img = cv2.resize(img,(224,224))\n",
    "x = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "x = np.array(x,dtype='float')\n",
    "x = x / 255\n",
    "y_pred = model.predict(np.expand_dims(x,0))\n",
    "y_pred = post_process(y_pred,priors,num_classes,input_H,input_W)\n",
    "print(y_pred)\n",
    "draw_detection(img,y_pred[0],class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video detection demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = \"data/cat_video.mp4\"\n",
    "result_file = \"res.avi\"\n",
    "cap= cv2.VideoCapture(video_file)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "frames = (int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "print('Input Video Size:',size,' Fps:',fps,' Frames:',frames)\n",
    "writer = cv2.VideoWriter(result_file,cv2.VideoWriter_fourcc(*'MJPG'), fps, size)\n",
    "success,frame = cap.read()\n",
    "count = 1\n",
    "while success:\n",
    "    x = cv2.resize(frame,dsize=(input_H,input_W),interpolation=cv2.INTER_CUBIC)\n",
    "    x = x / 255\n",
    "    y_pred = model.predict(np.expand_dims(x,0))[0]\n",
    "    y_pred [-4:] *= [*size,*size]\n",
    "    draw_detection(frame, y_pred,class_names,font_scale = 1)\n",
    "    writer.write(frame)\n",
    "    cv2.waitKey(1)\n",
    "    count += 1\n",
    "    if count%50==0:\n",
    "        print(y_pred)\n",
    "        plt.imshow(frame)\n",
    "        plt.show()\n",
    "        print('.',end='')\n",
    "    success,frame = cap.read()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
