{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "#From keras\n",
    "import keras\n",
    "from keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "from keras import optimizers\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import backend as K\n",
    "\n",
    "# From ssd_keras\n",
    "from SSD_loss import SSDLoss\n",
    "from importlib import reload\n",
    "#import cv2\n",
    "import pet_data\n",
    "import detection_nets\n",
    "import tensorflow as tf\n",
    "from pet_detector_help import *\n",
    "from matplotlib import pyplot as plt\n",
    "from drawing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_H = 224\n",
    "input_W = 224\n",
    "input_C = 3\n",
    "input_shape = (input_H, input_W, input_C)\n",
    "data_root = \"/home/cai/dataset/pets/\"\n",
    "extras =  ['S', 512 ]\n",
    "feature_map = [7,7,4,4,2,1]\n",
    "aspect_ratios = [[2,3],[2,3],[2,3],[2,3],[2],[2]] \n",
    "mbox =  [2 + len(ar) * 2 for ar in aspect_ratios]  # number of boxes per feature map location\n",
    "source_layers=[\"out_relu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot = data_root + \"annotations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare classnames file and train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abyssinian', 'american_bulldog', 'american_pit_bull_terrier', 'basset_hound', 'beagle', 'bengal', 'birman', 'bombay', 'boxer', 'british_shorthair', 'chihuahua', 'egyptian_mau', 'english_cocker_spaniel', 'english_setter', 'german_shorthaired', 'great_pyrenees', 'havanese', 'japanese_chin', 'keeshond', 'leonberger', 'maine_coon', 'miniature_pinscher', 'newfoundland', 'persian', 'pomeranian', 'pug', 'ragdoll', 'russian_blue', 'saint_bernard', 'samoyed', 'scottish_terrier', 'shiba_inu', 'siamese', 'sphynx', 'staffordshire_bull_terrier', 'wheaten_terrier', 'yorkshire_terrier']\n",
      "before ignore: 3680\n",
      "after ignore: 3671\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def generate_class_names(annot):\n",
    "    list_names = open(annot + '/trainval.txt').readlines()\n",
    "    class_names = []\n",
    "    for name in list_names:\n",
    "        name = name.lower()\n",
    "        p = name.rfind('_')\n",
    "        if not name[:p] in class_names:\n",
    "            class_names.append(name[:p])\n",
    "    print(class_names)\n",
    "    file = open(os.path.join(annot,'class_names.txt'),'w')\n",
    "    file.writelines([name + \"\\n\" for name in class_names ])\n",
    "generate_class_names(annot)\n",
    "pet_data.split_annotations(data_root,'trainval.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read classnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['background', 'abyssinian', 'american_bulldog', 'american_pit_bull_terrier', 'basset_hound', 'beagle', 'bengal', 'birman', 'bombay', 'boxer', 'british_shorthair', 'chihuahua', 'egyptian_mau', 'english_cocker_spaniel', 'english_setter', 'german_shorthaired', 'great_pyrenees', 'havanese', 'japanese_chin', 'keeshond', 'leonberger', 'maine_coon', 'miniature_pinscher', 'newfoundland', 'persian', 'pomeranian', 'pug', 'ragdoll', 'russian_blue', 'saint_bernard', 'samoyed', 'scottish_terrier', 'shiba_inu', 'siamese', 'sphynx', 'staffordshire_bull_terrier', 'wheaten_terrier', 'yorkshire_terrier']\n",
      "classes num 38\n"
     ]
    }
   ],
   "source": [
    "#read_class_names(annot):\n",
    "file = open(os.path.join(annot,'class_names.txt'))\n",
    "lines = open(os.path.join(annot,'class_names.txt')).readlines()\n",
    "class_names = [name[:-1] for name in lines]\n",
    "class_names.insert(0,'background')\n",
    "num_classes = len(class_names)\n",
    "print(class_names)\n",
    "print('classes num',num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................done\n",
      "x_train shape (2753, 224, 224, 3)  y_train_no_process shape (2753, 42)\n",
      "x_test shape (275, 224, 224, 3)  y_test_no_process shape (275, 42)\n"
     ]
    }
   ],
   "source": [
    "reload(pet_data)\n",
    "(x_train,y_train_no_process),(x_test,y_test_no_process) = pet_data.load_data(1,0.3,root=data_root,task = 'detection')\n",
    "print(\"x_train shape\",x_train.shape,\" y_train_no_process shape\",y_train_no_process.shape)\n",
    "print(\"x_test shape\",x_test.shape,\" y_test_no_process shape\",y_test_no_process.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate prior boxes and process y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_no_process.copy() #* [input_W,input_H,input_W,input_H]\n",
    "y_test = y_test_no_process.copy() #* [input_W,input_H,input_W,input_H]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw a sample of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "class_pos = 0\n",
    "for k,y in enumerate(y_train):\n",
    "    if class_pos == num_classes:\n",
    "        break\n",
    "    if y[class_pos] == 1:\n",
    "        idx.append(k)\n",
    "        class_pos += 1\n",
    "for i in  idx:\n",
    "    x = x_train[i].copy()\n",
    "    y = y_train_no_process[i].copy()\n",
    "    h,w,_ = x_train[i].shape \n",
    "    #print(y_train_no_process[:,1])\n",
    "    frame= (x * 255).astype('int32')\n",
    "    draw_detection(frame,y,class_names,box_color=(0,255,0),font_scale =0.5,draw_label=True)\n",
    "    plt.imshow(frame)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented data:label shape (4, 42)\n",
      "augmented data:image  [[[0.59607843 0.56470588 0.58039216]\n",
      "  [0.5372549  0.54901961 0.51372549]\n",
      "  [0.48627451 0.51372549 0.48627451]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.59607843 0.56470588 0.58039216]\n",
      "  [0.54509804 0.54901961 0.51764706]\n",
      "  [0.48627451 0.50588235 0.47843137]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.6        0.57647059 0.59215686]\n",
      "  [0.56470588 0.55294118 0.5372549 ]\n",
      "  [0.50196078 0.49803922 0.47058824]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.54509804 0.52941176 0.5372549 ]\n",
      "  [0.5372549  0.51372549 0.54509804]\n",
      "  [0.56862745 0.55686275 0.58823529]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.4627451  0.42745098 0.48627451]\n",
      "  [0.5372549  0.49803922 0.53333333]\n",
      "  [0.60392157 0.57254902 0.58823529]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.41960784 0.37254902 0.4627451 ]\n",
      "  [0.53333333 0.48627451 0.5254902 ]\n",
      "  [0.61960784 0.58039216 0.58431373]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "reload(pet_data)\n",
    "(train_flow,val_flow) = pet_data.data_augment(x_train,y_train,4,task = 'detection_single',num_classes = num_classes)\n",
    "image,labels = next(train_flow)\n",
    "print('augmented data:label shape',labels.shape)\n",
    "print('augmented data:image ',image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(detection_nets)\n",
    "base_name = \"mobilenetv2\"\n",
    "version_name = \"1.3\"\n",
    "source_name =\"out_relu\"\n",
    "build_model = detection_nets.build_simple_detection_net\n",
    "show_summary = False\n",
    "#Train\n",
    "phase = 'train' #training or testing\n",
    "alpha = 0.8 # location loss ratio\n",
    "epochs_per_stage = 8\n",
    "stages = 4\n",
    "epoch_decay = 0\n",
    "batch_size = 4\n",
    "verbose = True\n",
    "data_augment = True\n",
    "plot = True\n",
    "#Environment\n",
    "#clear_session = True\n",
    "#Learning params\n",
    "lr=1e-3\n",
    "decay=1e-6\n",
    "momentum=0.9\n",
    "validation_split = 0.25\n",
    "load_weights = False\n",
    "save_weights = True\n",
    "check_point = 1\n",
    "save_path = 'saved_weights'\n",
    "model_path = 'saved_models'\n",
    "log_file = \"log_detection\"\n",
    "log = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model with a backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_detection_mobilenetv2_1.3 has been built \n"
     ]
    }
   ],
   "source": [
    "#loss = SSDLoss().compute_loss\n",
    "if phase!='test' and phase!='train':\n",
    "    raise RuntimeError(\"Phase must be either train or test\")\n",
    "if epochs_per_stage < 1:\n",
    "    raise RuntimeError(\"Epochs per stage must be greater than 1\")\n",
    "if stages < 1:\n",
    "    raise RuntimeError(\"Stages must be greater than 1\")\n",
    "if phase == 'test' and load_weights != True:\n",
    "    print(\"Warning: phase is testing and load weights is not True\")\n",
    "if phase == 'train' and load_weights == False and check_point != 1:\n",
    "    print(\"Warning: Initial check point should be 1\")\n",
    "    check_point = 1\n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)\n",
    "if not os.path.isdir(model_path):\n",
    "    os.mkdir(model_path)\n",
    "import classification_nets\n",
    "reload(classification_nets)\n",
    "base_model = classification_nets.build_mobilenet_v2(input_shape=(input_H,input_W,input_C),output_num=num_classes)[1]\n",
    "base_model.load_weights(\"saved_weights/mobilenet_v2_22.h5\")\n",
    "#base_model =  keras.applications.mobilenet_v2.MobileNetV2(input_shape=(input_H,input_W,input_C), alpha=1.0, \n",
    "#                                                          depth_multiplier=1, include_top=True, \n",
    "#                                                          weights='imagenet', input_tensor=None, pooling=None, classes=1000)\n",
    "#freeze(base_model,50)\n",
    "model_name,model = build_model(base_model,source_name,num_classes,version_name,base_name)\n",
    "if show_summary:\n",
    "    if log:\n",
    "        json_string = model.to_json()\n",
    "        model_file = open(model_path  + '/' + model_name + version_name,'w')\n",
    "        model_file.write(json_string)\n",
    "        model_file.close()\n",
    "    model.summary()\n",
    "print(model_name,'has been built ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Loss(y_true,y_pred):\n",
    "    a = alpha\n",
    "#    y_pred[:,-4:] * [input_W,input_H,input_W,input_H]\n",
    "    pos_mask = 1 - y_true[:,0] \n",
    "    log_loss = -tf.reduce_sum(tf.reduce_sum(y_true[:,:-4] * tf.log(y_pred[:,:-4]), axis=-1))\n",
    "#    log_loss = tf.reduce_sum(log_loss * pos_mask)\n",
    "    mse_loss = tf.square(y_true[:,-4:] * [input_W,input_H,input_W,input_H] - y_pred[:,-4:])\n",
    "    mse_loss = tf.reduce_sum(mse_loss * pos_mask)\n",
    "    total_loss =  (1 + a ) * mse_loss + (1 - a ) * log_loss \n",
    "    return log_loss\n",
    "model.compile(loss=Loss,optimizer=optimizers.SGD(lr=lr,decay=decay,momentum=momentum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check whether y train、y_test and output of model  have the same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.output.get_shape(),y_train.shape)\n",
    "assert((np.array(model.output.get_shape().as_list()[1:]) == np.array(y_train.shape[1:])).all())\n",
    "assert((np.array(model.output.get_shape().as_list()[1:]) == np.array(y_test.shape[1:])).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train or Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name simple_detection_mobilenetv2_1.3 \n",
      "start fitting..  \n",
      "stages: 4  epochs_per_stage: 8  plot_history: True  data_augmented: True \n",
      "trainset size: 2753  validation_split: 0.25 \n",
      "learning rate: 0.001  decay: 1e-06  momentum: 0.9 \n",
      "initial checkpoint: 1 \n",
      "load weight: False\n",
      "Stage  1 / 4\n",
      "Epoch num 8\n",
      "Epoch 1/8\n",
      "394/688 [================>.............] - ETA: 21s - loss: 12.3181"
     ]
    }
   ],
   "source": [
    "reload(pet_data)\n",
    "try:\n",
    "    if log:\n",
    "        file = open(log_file,'a+')\n",
    "    if load_weights:\n",
    "        model.load_weights(save_path + '/' + model_name + '_' + str(check_point) + \".h5\")\n",
    "        print(\"weights loaded from check point\",check_point)\n",
    "        if phase == 'train':check_point += 1\n",
    "    if phase == 'train':\n",
    "        info =('model name' ,model_name , \\\n",
    "               '\\nstart fitting.. ' , '\\nstages:' , stages, ' epochs_per_stage:',epochs_per_stage, ' plot_history:' ,plot, ' data_augmented:', data_augment, \\\n",
    "               '\\ntrainset size:', len(y_train), ' validation_split:',validation_split,\\\n",
    "               '\\nlearning rate:' ,lr  ,' decay:' ,decay , ' momentum:' ,momentum ,  \\\n",
    "               '\\ninitial checkpoint:', check_point ,  \\\n",
    "               '\\nload weight:' ,load_weights)\n",
    "        if verbose:\n",
    "            print(*info)\n",
    "        if log:\n",
    "            print(*info,file=file)\n",
    "        epochs = epochs_per_stage\n",
    "        if data_augment:\n",
    "            (train_flow,val_flow) = pet_data.data_augment(x_train,y_train,batch_size,validation_split,'detection_single',num_classes = num_classes)\n",
    "            steps_per_epoch = len(x_train) / batch_size\n",
    "            validation_steps = int(len(x_train) * validation_split) / batch_size\n",
    "        for i in range(1,1+stages):\n",
    "            if verbose:\n",
    "                print(\"Stage \",i,\"/\",stages)\n",
    "                print(\"Epoch num\",epochs)\n",
    "            if log:\n",
    "                print(\"Stage \",i,\"/\",stages,file=file)\n",
    "                print(\"Epoch num\",epochs,file=file)\n",
    "            if not data_augment:\n",
    "                history = model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs, verbose = verbose, validation_split = validation_split)\n",
    "            else:\n",
    "                history = model.fit_generator(train_flow,steps_per_epoch = steps_per_epoch, validation_data = val_flow, validation_steps = validation_steps, epochs = epochs)\n",
    "            \n",
    "            path = save_path + '/' + model_name + '_' + str(check_point) + \".h5\"\n",
    "            if save_weights:\n",
    "                if verbose:\n",
    "                    print(\"save at\",path)\n",
    "                model.save_weights(path)\n",
    "                check_point += 1 \n",
    "            ac = evaluate(model,x_test,y_test)\n",
    "            if verbose:\n",
    "                print(ac)\n",
    "            if log:\n",
    "                print(ac,file=file)\n",
    "            if plot:\n",
    "                plot_history(history)\n",
    "            epochs = epochs - epoch_decay // stages\n",
    "    elif phase =='test':\n",
    "        if verbose:\n",
    "            print('start evaluating')\n",
    "        loss = model.evaluate(x=x_test,y=y_test)\n",
    "        ac = evaluate(model,x_test,y_test)\n",
    "        if verbose:\n",
    "            print('loss',round(loss,5))\n",
    "            print('ac',ac)\n",
    "        if log:\n",
    "            print('loss',round(loss,5),file=file)\n",
    "            print('ac',ac,file=file)\n",
    "except Exception as ex:\n",
    "    if load_weights and phase == 'train': check_point -= 1\n",
    "    file.close()\n",
    "    raise ex\n",
    "   # model.save_weights(model_name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 7s 25ms/step\n",
      "loss 121.20606\n",
      "{'loc accuracy': 0.0182, 'class accuracy': 0.0218, 'accuracy ': 0.0}\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x=x_test,y=y_test)\n",
    "print('loss',round(result,5))\n",
    "print(evaluate(model,x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Set hyper params and run all above from here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a test image and do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_idx = np.where(y_test[:,0] == 1)[0]\n",
    "test_idx = [i*100 + j for i in range(4) for j in range(0,15)]\n",
    "x = x_test\n",
    "y = y_test\n",
    "y_pred_no_process = model.predict(x[test_idx])\n",
    "y_pred = y_pred_no_process.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw for single object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,prediction  in enumerate(y_pred):\n",
    "    #print(prediction)\n",
    "    # Extract x from test set\n",
    "    print(\"image: \",k)\n",
    "    frame = (x[test_idx[k]] * 255).astype('int32')\n",
    "    print(frame.shape)\n",
    "    score = np.max(prediction[:-4])\n",
    "    spec = np.argmax(prediction[:-4])\n",
    "    print('loc pred',np.round(prediction[-4:],3))\n",
    "    print('class pred',class_names[spec],'score',score)\n",
    "    y_true = y[test_idx[k]]\n",
    "    spec = np.argmax(y_true[:-4])\n",
    "    print('loc truth',np.round(y_true[-4:],3))\n",
    "    print('class truth',class_names[spec])\n",
    "    draw_detection(frame,prediction,class_names)\n",
    "    draw_detection(frame,y[test_idx[k]],class_names,box_color = (0,255,0))\n",
    "    plt.imshow(frame)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw for multiobject detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,prediction  in enumerate(y_pred):\n",
    "    #print(prediction)\n",
    "    # Extract x from test set\n",
    "    print(\"image: \",k)\n",
    "    frame = (test_set[0][test_idx[k]]*255).astype('int32')\n",
    "    for c,detections in enumerate(prediction):\n",
    "        if len(detections) == 0:\n",
    "            continue\n",
    "        class_name = class_names[c]\n",
    "        for detection in detections:\n",
    "            score = detection[0]\n",
    "            bbox = detection[1:] * input_H#corner\n",
    "            print(class_name,score,bbox)\n",
    "            bbox = bbox.astype('int32')\n",
    "            draw_detection(frame,bbox,score,class_name,box_width = 3)\n",
    "    plt.imshow(frame)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = \"data/dog5.jpg\"\n",
    "img = cv2.imread(img_file)\n",
    "img = cv2.resize(img,(224,224))\n",
    "print(img.shape)\n",
    "x = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "x = np.array(x,dtype='float')\n",
    "x = x / 255\n",
    "y_pred = model.predict(np.expand_dims(x,0))[0]\n",
    "print(np.max(y_pred))\n",
    "draw_detection(img,y_pred,class_names,box_width=2,font_scale=0.5)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = \"data/cats_video.mp4\"\n",
    "result_file = \"res.avi\"\n",
    "cap= cv2.VideoCapture(video_file)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "frames = (int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "print('Input Video Size:',size,' Fps:',fps,' Frames:',frames)\n",
    "writer = cv2.VideoWriter(result_file,cv2.VideoWriter_fourcc(*'MJPG'), fps, size)\n",
    "success,frame = cap.read()\n",
    "count = 1\n",
    "while success:\n",
    "    x = cv2.resize(frame,dsize=(input_H,input_W),interpolation=cv2.INTER_CUBIC)\n",
    "    x = x / 255\n",
    "    y_pred = model.predict(np.expand_dims(x,0))[0]\n",
    "    draw_detection(frame, y_pred,class_names,font_scale = 1)\n",
    "    writer.write(frame)\n",
    "    cv2.waitKey(1)\n",
    "    count += 1\n",
    "    if count%50==0:\n",
    "        plt.imshow(frame)\n",
    "        plt.show()\n",
    "        print('.',end='')\n",
    "    success,frame = cap.read()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
